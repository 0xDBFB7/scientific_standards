
To the public, anything in a pdf format and with big words is now science, even if it completely defies every best practice. Poor-quality science will undermine itself.

You lose the rights to contributed content - will that work?




Selected documents

it is hoped that eventually this might be machine-readable and integrated with hargrave in some fashion, 
if that ever becomes more than a pipe dream.






https://en.wikipedia.org/wiki/Joan_Curran

meta_standard (for adding new standards)


Sections:


describe also the context and position in terms of the literature; superceding techniques,


"Successful" uses 
"Unsuccessful" uses 

Reviewed by:

Daniel [non-expert, unverified]

Permission to contact (in accordance with the guidelines): 


"Positive" benchmark

"Negative" benchmark

Probably it will become dormant in a few weeks and nothing will matter.

Simple, orthogonal tests for all reagents or supplies that can be performed by 
as many people as possible to put everything into a "known state";
regular audits?


Must track progress as rapidly as possible. 
There are few central clearinghouses for the state-of-the-art!



It might end up being a total waste of time!


Books regarding techniques are probably also good ways to get the same knowledge.


When adding, you can agree to be added to a mailing list. If changes are requested, you 
may be contacted to obtain approval.


unit and integration tests for science

On mailing list and identies


On the other hand, a list of the contact information of every expert in the field seems 
 rife for abuse



of course, science lies on a wide distribution from true experts producing unassailable results
to poor-quality. Judging based on the bottom tail gives a 


best practices are often buried in decades of 

if you want a good result, this is how you do it.

Paper writing itself:

orcid, 

(of course, standards themselves might proliferate!)



for materials science, this might be a certain test coupon.
For batteries, a very specific technical performance metric across chemistries.


To obtain a certain hardness metric (say, Rockwell), a certain number of procedures are dictated to obtain 
a consistent result. 


"best available" experiment design for the job.

SHOULD Design Guideline for Microfluidic Device and
Component Interfaces




"In particular, they MUST only be used where it is
   actually required for interoperation or to limit behavior which has
   potential for causing harm (e.g., limiting retransmisssions)  For
   example, they must not be used to try to impose a particular method
   on implementors where the method is not required for
   interoperability."
   




 and, indeed, monumental people are 

TEM laser paper

However, a cursory or Scientific Reports produces a most depressing opposition.
The accuracy very probably remained unchanged, but the volume ; and so the literature has devolved into a kind of blur;
it no longer offers any guidance on what problems to attack, which directions are fruitful.

reduce down to the minimum requirements and most easily implementable; to drive towards
greater "stability".

of course, judging by the most infamous examples doesn't do justice to the best science.
Still, 




 
These are fundamental parts of science, but not everyon




tech-transfer.



add biological microwave spectrometry 

add Pakhomov standard waveguide
add "data" section

add mosquito repellant test standard culture
add laser breakdown "comment on" article

cite microfluidic standard

At bottom of standard, document changelog with previous deficiencies
benchmarks - there must be a way to justifiably transfer to new equipment or update a standard.
I guess that means you have to repeat one or more of the most demanding previous positive and negative
tests and ensure that you 



One-tailed or two-tailed test?


.standard.md
.culture.py

RATIONALE

PERSPECTIVE [DC]



ab initio if possible (relying as little as possible on specific manufacturers, reagents, etc),
 which is easy to say but hard to implement in practice.

 
should tell the novice all the things they must know and be aware of to 


culture template / standard database inside the main git repo - for each field or experiment
has best practices built in, tells you what to check
shouldn't require a PR to change - maybe a contact form built in?

Contact information for certain culture templates are built in; experts in certain fields can 
 explicitly agree to have their contact info added to check stuff?


having a list of all contact info for every expert in a field seems rife for abuse - seperate personal table of emails 
voting
everyone must have an ORCiD?

besides the "expert list" (or maybe instead),
"user list" so breaking changes can be requested for comment - maybe even publications in the field?

where "user list" doesn't mean breaking changes

request for comment, "Voting" on changes


PR - set of standards to not mislead PR based on evidence


all people following the standard must use the latest version available at the beginning of work.
it is probably too much to ask for updates while performing the experiment,
but it should be acknowledged that from time to time invalidate 

if an expert can immediately identify problems in a study,
then it seems that some authors nowadays are operating without the same set of knowledge

can you trust the fourth estate

nist colloquium can we trust the estate


the process which we are following is itself, in a weird way, not scientific. problems 
keep happening.



